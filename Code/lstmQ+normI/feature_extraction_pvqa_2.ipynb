{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_extraction_pvqa-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maryamhashemi/Persian_VQA/blob/master/feature_extraction_pvqa_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN6UmcdtMNd1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "69bea683-79a4-46f1-a66c-8f3c59173cb1"
      },
      "source": [
        "!pip install deepdish\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepdish\n",
            "  Downloading https://files.pythonhosted.org/packages/6e/39/2a47c852651982bc5eb39212ac110284dd20126bdc7b49bde401a0139f5d/deepdish-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deepdish) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from deepdish) (1.4.1)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.6/dist-packages (from deepdish) (3.4.4)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.6/dist-packages (from tables->deepdish) (2.7.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from tables->deepdish) (1.15.0)\n",
            "Installing collected packages: deepdish\n",
            "Successfully installed deepdish-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnFHPN8NI6RB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# #If the downloaded file is a zip file than you can use below function to unzip it.\n",
        "def unzip(dir,where):\n",
        "    with ZipFile(dir) as zipf:\n",
        "        zipf.extractall(where)\n",
        "    print(\"File Unzipped!\")\n",
        "# uncompress_features_labels('/content/drive/My Drive/Persian_VQA/mscoco_train2014_english.zip','/content/drive/My Drive/Persian_VQA/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsodIROMItFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "DROPOUT_RATE = 0.5\n",
        "EMBEDDING_DIM = 300\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 256\n",
        "SEQ_LENGTH = 100\n",
        "VOCAB_SIZE = 1000\n",
        "OOV_TOK = \"<OOV>\"\n",
        "\n",
        "BASE_PATH = '/content/drive/My Drive/Persian_VQA/'\n",
        "QUESTION_TRAIN_PATH =   os.path.join(BASE_PATH, 'OpenEnded_mscoco_train2014_questions.json')\n",
        "ANNOTATION_TRAIN_PATH = os.path.join(BASE_PATH, 'mscoco_train2014_annotations.json')\n",
        "# IMAGE_TRAIN_PATH = os.path.join(BASE_PATH, 'train_images_1000')\n",
        "IMAGE_TRAIN_PATH = os.path.join('/content/', 'train2014')\n",
        "\n",
        "QUESTION_VAL_PATH =   os.path.join(BASE_PATH, 'OpenEnded_mscoco_val2014_questions.json')\n",
        "ANNOTATION_VAL_PATH = os.path.join(BASE_PATH, 'mscoco_val2014_annotations.json')\n",
        "# IMAGE_VAL_PATH = os.path.join(BASE_PATH, 'val_images_500')\n",
        "IMAGE_VAL_PATH = os.path.join('/content/', 'val2014')\n",
        "\n",
        "QUESTION_TEST_PATH =   os.path.join(BASE_PATH, '...')\n",
        "ANNOTATION_TEST_PATH = os.path.join(BASE_PATH, '...')\n",
        "# IMAGE_TEST_PATH = os.path.join(BASE_PATH, 'val_images_500')\n",
        "IMAGE_TEST_PATH = os.path.join('/content/', 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E56u_w2JC1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "1d5b0d2f-d4d5-4496-91e3-896719336465"
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/train2014.zip\n",
        "# !wget http://images.cocodataset.org/zips/val2014.zip\n",
        "# !wget http://images.cocodataset.org/zips/test2015.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-12 04:48:09--  http://images.cocodataset.org/zips/train2014.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.162.35\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.162.35|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13510573713 (13G) [application/zip]\n",
            "Saving to: ‘train2014.zip’\n",
            "\n",
            "train2014.zip       100%[===================>]  12.58G  35.0MB/s    in 5m 9s   \n",
            "\n",
            "2020-08-12 04:53:19 (41.7 MB/s) - ‘train2014.zip’ saved [13510573713/13510573713]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU3oEHrfJDWJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9e45ed39-6288-4e37-a42b-de614803fcdc"
      },
      "source": [
        "unzip('/content/train2014.zip','/content/')\n",
        "# unzip('/content/val2014.zip','/content/')\n",
        "# unzip('/content/test2015.zip','/content/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Unzipped!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4ZvjgomThMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgXrl4yOFSns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.nasnet import NASNetLarge, preprocess_input\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVyNf4FyBd10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.resnet import ResNet152,preprocess_input \n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiXVJaDQcCKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = InceptionResNetV2(weights='imagenet', pooling='avg' , include_top=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsAqhbH-cpyA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8c31c3b0-587a-4d07-e155-68345b9af672"
      },
      "source": [
        "base_model.layers[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x7fdb82c33198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr-z47dwHviR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46212669-4cfb-425d-c67f-a89cdb6c408c"
      },
      "source": [
        "import tensorflow\n",
        "import os\n",
        "import re\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import deepdish as dd\n",
        "# from constants import *\n",
        "from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.applications import VGG19\n",
        "# from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# from tensorflow.keras.applications import ResNet152\n",
        "# from tensorflow.keras.applications import preprocess_input as pr_152\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s:%(name)s:%(message)s')\n",
        "\n",
        "file_handler = logging.FileHandler('prepare_images.log')\n",
        "file_handler.setFormatter(formatter)\n",
        "\n",
        "stream_handler = logging.StreamHandler()\n",
        "\n",
        "logger.addHandler(file_handler)\n",
        "logger.addHandler(stream_handler)\n",
        "\n",
        "\n",
        "def read_image_paths(dir_path):\n",
        "    \"\"\"\n",
        "    read the path of images in 'dir_path' and return a dictionary mapping image_id to image path.\n",
        "    Arguments:\n",
        "    dir_path -- a directory that consists of images.\n",
        "    Return:\n",
        "    ims -- a dictionary that maps image_id to image path.\n",
        "    \"\"\"\n",
        "    ims = {}\n",
        "\n",
        "    for filename in os.listdir(dir_path):\n",
        "        if filename.endswith('.jpg'):\n",
        "            image_id = int(re.findall('\\d+', filename)[1])\n",
        "            ims[image_id] = os.path.join(dir_path, filename)\n",
        "\n",
        "    return ims\n",
        "\n",
        "\n",
        "def load_and_proccess_image(image_path, model, image_size):\n",
        "    \"\"\"\n",
        "    load and preprocess image, then extract features using model.\n",
        "    Arguments:\n",
        "    image_path -- a string that is image path.\n",
        "    model -- a cnn model for extracting features from image.\n",
        "    image_size -- expected size of image after loading.\n",
        "    Return:\n",
        "    features -- extracted features from image.\n",
        "    \"\"\"\n",
        "\n",
        "    im = load_img(image_path, target_size=image_size)\n",
        "    x = img_to_array(im)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x =  preprocess_input(x)\n",
        "\n",
        "    features = model.predict(x)\n",
        "    # x=np.squeeze(features[0])\n",
        "\n",
        "    return features[0]\n",
        "\n",
        "\n",
        "def extract_features(paths):\n",
        "    \"\"\"\n",
        "    extract features from images using VGG19.\n",
        "    Arguments:\n",
        "    paths -- a dictionary that maps image_ids to image paths.\n",
        "    Return:\n",
        "    ims -- a dictionary that saves mapping between image_ids and image features.\n",
        "    \"\"\"\n",
        "    ims = {}\n",
        "    # base_model = InceptionResNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
        "    # fl = tensorflow.keras.layers.Flatten()(base_model.output)\n",
        "    # model = Model(inputs=base_model.input,\n",
        "    #               outputs=fl)\n",
        "    base_model = ResNet152(weights='imagenet', include_top=False, pooling='avg')\n",
        "    # fl = tensorflow.keras.layers.Flatten()(base_model.output)\n",
        "    model = Model(inputs=base_model.input,\n",
        "                  outputs=base_model.output)\n",
        "\n",
        "\n",
        "    num_ims = len(paths)\n",
        "    for i, (image_id, image_path) in enumerate(paths.items()):\n",
        "        ims[image_id] = load_and_proccess_image(\n",
        "            image_path, model, (331, 331))\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            logger.info(\"extract features from %i/%i images.\" %\n",
        "                        (i + 1, num_ims))\n",
        "    return ims\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_train_image_paths():\n",
        "    return read_image_paths(IMAGE_TRAIN_PATH)\n",
        "\n",
        "\n",
        "def get_val_image_paths():\n",
        "    return read_image_paths(IMAGE_VAL_PATH)\n",
        "\n",
        "\n",
        "def get_test_image_paths():\n",
        "    return read_image_paths(IMAGE_TEST_PATH)\n",
        "\n",
        "\n",
        "def save_train_features():\n",
        "    \"\"\"\n",
        "    extract features from train images using VGG19 and save them as .csv and .h5 file.\n",
        "    \"\"\"\n",
        "    logger.info(\"Start: extract features from train images.\")\n",
        "    train_ims = extract_features(get_train_image_paths())\n",
        "    logger.info(\"End: extract features from train images.\")\n",
        "\n",
        "    # .csv\n",
        "    # df = pd.DataFrame(train_ims)\n",
        "    # df.to_csv('dataset/vgg19/X_train_ims_VGG19.csv')\n",
        "    # logger.info('saved in \\\"X_train_ims_VGG19.csv\\\".')\n",
        "\n",
        "    # .h5\n",
        "    dd.io.save('train_full_features_inceptionresnet2_dict.h5',\n",
        "               train_ims, compression=None)\n",
        "    logger.info('saved in \\\"X_train_ims_VGG19.h5\\\".')\n",
        "\n",
        "\n",
        "def save_val_features():\n",
        "    \"\"\"\n",
        "    extract features from validation images using VGG19 and save them as .csv and .h5 file.\n",
        "    \"\"\"\n",
        "    logger.info(\"Start: extract features from val images.\")\n",
        "    val_ims = extract_features(get_val_image_paths())\n",
        "    logger.info(\"End: extract features from val images.\")\n",
        "\n",
        "    # # .csv\n",
        "    # df = pd.DataFrame(val_ims)\n",
        "    # df.to_csv('X_val_ims_VGG19.csv')\n",
        "    # logger.info('saved in \\\"X_val_ims_VGG19.csv\\\".')\n",
        "\n",
        "    # .h5\n",
        "    dd.io.save('val_full_features_inceptionresnet2_dict.h5',\n",
        "               val_ims, compression=None)\n",
        "    logger.info('saved in \\\"X_val_ims_VGG19.h5\\\".')\n",
        "\n",
        "\n",
        "def save_test_features():\n",
        "    \"\"\"\n",
        "    extract features from test images using VGG19 and save them as .csv and .h5 file.\n",
        "    \"\"\"\n",
        "    logger.info(\"Start: extract features from test images.\")\n",
        "    test_ims = extract_features(get_test_image_paths())\n",
        "    logger.info(\"End: extract features from test images.\")\n",
        "\n",
        "    # .csv\n",
        "    df = pd.DataFrame(test_ims)\n",
        "    df.to_csv('X_test_ims_VGG19.csv')\n",
        "    logger.info('saved in \\\"X_test_ims_VGG19.csv\\.\"')\n",
        "\n",
        "    # .h5\n",
        "    dd.io.save('X_test_ims_VGG19.h5',\n",
        "               test_ims, compression=None)\n",
        "    logger.info('saved in \\\"X_test_ims_VGG19.h5\\\".')\n",
        "\n",
        "\n",
        "save_train_features()\n",
        "# save_val_features()\n",
        "# save_test_features()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "extract features from 65600/82783 images.\n",
            "extract features from 65700/82783 images.\n",
            "extract features from 65800/82783 images.\n",
            "extract features from 65900/82783 images.\n",
            "extract features from 66000/82783 images.\n",
            "extract features from 66100/82783 images.\n",
            "extract features from 66200/82783 images.\n",
            "extract features from 66300/82783 images.\n",
            "extract features from 66400/82783 images.\n",
            "extract features from 66500/82783 images.\n",
            "extract features from 66600/82783 images.\n",
            "extract features from 66700/82783 images.\n",
            "extract features from 66800/82783 images.\n",
            "extract features from 66900/82783 images.\n",
            "extract features from 67000/82783 images.\n",
            "extract features from 67100/82783 images.\n",
            "extract features from 67200/82783 images.\n",
            "extract features from 67300/82783 images.\n",
            "extract features from 67400/82783 images.\n",
            "extract features from 67500/82783 images.\n",
            "extract features from 67600/82783 images.\n",
            "extract features from 67700/82783 images.\n",
            "extract features from 67800/82783 images.\n",
            "extract features from 67900/82783 images.\n",
            "extract features from 68000/82783 images.\n",
            "extract features from 68100/82783 images.\n",
            "extract features from 68200/82783 images.\n",
            "extract features from 68300/82783 images.\n",
            "extract features from 68400/82783 images.\n",
            "extract features from 68500/82783 images.\n",
            "extract features from 68600/82783 images.\n",
            "extract features from 68700/82783 images.\n",
            "extract features from 68800/82783 images.\n",
            "extract features from 68900/82783 images.\n",
            "extract features from 69000/82783 images.\n",
            "extract features from 69100/82783 images.\n",
            "extract features from 69200/82783 images.\n",
            "extract features from 69300/82783 images.\n",
            "extract features from 69400/82783 images.\n",
            "extract features from 69500/82783 images.\n",
            "extract features from 69600/82783 images.\n",
            "extract features from 69700/82783 images.\n",
            "extract features from 69800/82783 images.\n",
            "extract features from 69900/82783 images.\n",
            "extract features from 70000/82783 images.\n",
            "extract features from 70100/82783 images.\n",
            "extract features from 70200/82783 images.\n",
            "extract features from 70300/82783 images.\n",
            "extract features from 70400/82783 images.\n",
            "extract features from 70500/82783 images.\n",
            "extract features from 70600/82783 images.\n",
            "extract features from 70700/82783 images.\n",
            "extract features from 70800/82783 images.\n",
            "extract features from 70900/82783 images.\n",
            "extract features from 71000/82783 images.\n",
            "extract features from 71100/82783 images.\n",
            "extract features from 71200/82783 images.\n",
            "extract features from 71300/82783 images.\n",
            "extract features from 71400/82783 images.\n",
            "extract features from 71500/82783 images.\n",
            "extract features from 71600/82783 images.\n",
            "extract features from 71700/82783 images.\n",
            "extract features from 71800/82783 images.\n",
            "extract features from 71900/82783 images.\n",
            "extract features from 72000/82783 images.\n",
            "extract features from 72100/82783 images.\n",
            "extract features from 72200/82783 images.\n",
            "extract features from 72300/82783 images.\n",
            "extract features from 72400/82783 images.\n",
            "extract features from 72500/82783 images.\n",
            "extract features from 72600/82783 images.\n",
            "extract features from 72700/82783 images.\n",
            "extract features from 72800/82783 images.\n",
            "extract features from 72900/82783 images.\n",
            "extract features from 73000/82783 images.\n",
            "extract features from 73100/82783 images.\n",
            "extract features from 73200/82783 images.\n",
            "extract features from 73300/82783 images.\n",
            "extract features from 73400/82783 images.\n",
            "extract features from 73500/82783 images.\n",
            "extract features from 73600/82783 images.\n",
            "extract features from 73700/82783 images.\n",
            "extract features from 73800/82783 images.\n",
            "extract features from 73900/82783 images.\n",
            "extract features from 74000/82783 images.\n",
            "extract features from 74100/82783 images.\n",
            "extract features from 74200/82783 images.\n",
            "extract features from 74300/82783 images.\n",
            "extract features from 74400/82783 images.\n",
            "extract features from 74500/82783 images.\n",
            "extract features from 74600/82783 images.\n",
            "extract features from 74700/82783 images.\n",
            "extract features from 74800/82783 images.\n",
            "extract features from 74900/82783 images.\n",
            "extract features from 75000/82783 images.\n",
            "extract features from 75100/82783 images.\n",
            "extract features from 75200/82783 images.\n",
            "extract features from 75300/82783 images.\n",
            "extract features from 75400/82783 images.\n",
            "extract features from 75500/82783 images.\n",
            "extract features from 75600/82783 images.\n",
            "extract features from 75700/82783 images.\n",
            "extract features from 75800/82783 images.\n",
            "extract features from 75900/82783 images.\n",
            "extract features from 76000/82783 images.\n",
            "extract features from 76100/82783 images.\n",
            "extract features from 76200/82783 images.\n",
            "extract features from 76300/82783 images.\n",
            "extract features from 76400/82783 images.\n",
            "extract features from 76500/82783 images.\n",
            "extract features from 76600/82783 images.\n",
            "extract features from 76700/82783 images.\n",
            "extract features from 76800/82783 images.\n",
            "extract features from 76900/82783 images.\n",
            "extract features from 77000/82783 images.\n",
            "extract features from 77100/82783 images.\n",
            "extract features from 77200/82783 images.\n",
            "extract features from 77300/82783 images.\n",
            "extract features from 77400/82783 images.\n",
            "extract features from 77500/82783 images.\n",
            "extract features from 77600/82783 images.\n",
            "extract features from 77700/82783 images.\n",
            "extract features from 77800/82783 images.\n",
            "extract features from 77900/82783 images.\n",
            "extract features from 78000/82783 images.\n",
            "extract features from 78100/82783 images.\n",
            "extract features from 78200/82783 images.\n",
            "extract features from 78300/82783 images.\n",
            "extract features from 78400/82783 images.\n",
            "extract features from 78500/82783 images.\n",
            "extract features from 78600/82783 images.\n",
            "extract features from 78700/82783 images.\n",
            "extract features from 78800/82783 images.\n",
            "extract features from 78900/82783 images.\n",
            "extract features from 79000/82783 images.\n",
            "extract features from 79100/82783 images.\n",
            "extract features from 79200/82783 images.\n",
            "extract features from 79300/82783 images.\n",
            "extract features from 79400/82783 images.\n",
            "extract features from 79500/82783 images.\n",
            "extract features from 79600/82783 images.\n",
            "extract features from 79700/82783 images.\n",
            "extract features from 79800/82783 images.\n",
            "extract features from 79900/82783 images.\n",
            "extract features from 80000/82783 images.\n",
            "extract features from 80100/82783 images.\n",
            "extract features from 80200/82783 images.\n",
            "extract features from 80300/82783 images.\n",
            "extract features from 80400/82783 images.\n",
            "extract features from 80500/82783 images.\n",
            "extract features from 80600/82783 images.\n",
            "extract features from 80700/82783 images.\n",
            "extract features from 80800/82783 images.\n",
            "extract features from 80900/82783 images.\n",
            "extract features from 81000/82783 images.\n",
            "extract features from 81100/82783 images.\n",
            "extract features from 81200/82783 images.\n",
            "extract features from 81300/82783 images.\n",
            "extract features from 81400/82783 images.\n",
            "extract features from 81500/82783 images.\n",
            "extract features from 81600/82783 images.\n",
            "extract features from 81700/82783 images.\n",
            "extract features from 81800/82783 images.\n",
            "extract features from 81900/82783 images.\n",
            "extract features from 82000/82783 images.\n",
            "extract features from 82100/82783 images.\n",
            "extract features from 82200/82783 images.\n",
            "extract features from 82300/82783 images.\n",
            "extract features from 82400/82783 images.\n",
            "extract features from 82500/82783 images.\n",
            "extract features from 82600/82783 images.\n",
            "extract features from 82700/82783 images.\n",
            "End: extract features from train images.\n",
            "saved in \"X_train_ims_VGG19.h5\".\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKHJDoejQmj7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "7bcbbaf6-f005-4946-9c2a-932d6c9731f9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeAsYvVWABHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/train_full_features_resnet152_dict.h5 /content/drive/My\\ Drive/parssoftco_PVQA3/train_full_features_resnet152_dict.h5 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKuWf-XtGTdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/train2014/ #/content/drive/My Drive/parssoftco_PVQA3/val_full_features_VGG19_dict.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui4f1gh6DNeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_and_proccess_image2(image_path, model, image_size):\n",
        "    \"\"\"\n",
        "    load and preprocess image, then extract features using model.\n",
        "    Arguments:\n",
        "    image_path -- a string that is image path.\n",
        "    model -- a cnn model for extracting features from image.\n",
        "    image_size -- expected size of image after loading.\n",
        "    Return:\n",
        "    features -- extracted features from image.\n",
        "    \"\"\"\n",
        "\n",
        "    im = load_img(image_path, target_size=image_size)\n",
        "    x = img_to_array(im)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x =  preprocess_input(x)\n",
        "\n",
        "    features = model.predict(x)\n",
        "    # x=np.squeeze(features[0])\n",
        "\n",
        "    return features[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKUt60EY3jEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import deepdish as dd\n",
        "# from constants import *\n",
        "from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.applications import VGG19\n",
        "# from tensorflow.keras.applications import VGG16\n",
        "# from tensorflow.keras.applications.vgg16 import preprocess_input as er\n",
        "# from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "def extract_features_one(image_path):\n",
        "    \"\"\"\n",
        "    extract features from images using VGG19.\n",
        "    Arguments:\n",
        "    paths -- a dictionary that maps image_ids to image paths.\n",
        "    Return:\n",
        "    ims -- a dictionary that saves mapping between image_ids and image features.\n",
        "    \"\"\"\n",
        "    ims = {}\n",
        "    base_model = InceptionResNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
        "    fl = tensorflow.keras.layers.Flatten()(base_model.output)\n",
        "    model = Model(inputs=base_model.input,\n",
        "                  outputs=fl)\n",
        "\n",
        "    \n",
        "    \n",
        "    # base_model = VGG16(weights='imagenet', include_top=True)\n",
        "    # model = Model(inputs=base_model.input,\n",
        "    #               outputs=base_model.get_layer('fc2').output)\n",
        "\n",
        "    image_paths = read_image_paths(IMAGE_TRAIN_PATH)\n",
        "\n",
        "    \n",
        "    ims= load_and_proccess_image2(image_paths[487025], model, (229, 229))\n",
        "\n",
        "\n",
        "    return ims"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR7zITkA3w_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q=extract_features_one('/content/train2014/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1LT4-NO5HBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "471fb88a-62d7-442d-e203-1e3225796877"
      },
      "source": [
        "q.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1536,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI8jhfVe2Xzo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e0dec7b5-f432-4b4f-93a0-dbeef6dd7c95"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.138524 , 6.1470633, 0.       , ..., 0.       , 0.       ,\n",
              "       0.       ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xws0yMQ5Txg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d1b28d3e-4869-443c-a257-c7caa3a779e9"
      },
      "source": [
        "q==a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True, ...,  True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLGNfjLqNsNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import deepdish as dd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrWSQIlz2ZMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e93da7fc-d177-496f-f651-5cf36be28341"
      },
      "source": [
        "b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.       , 1.0902787, 0.       , ..., 0.       , 0.       ,\n",
              "       0.       ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swA4x9XR1v3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_old_us=dd.io.load('/content/drive/My Drive/parssoftco_PVQA3/train_imid_to_feats_dict.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcV7K4K_zR3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict=dd.io.load('/content/drive/My Drive/parssoftco_PVQA3/train_full_features_VGG19_dict.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvQg-E-L2kJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c5f3530-50d4-4f53-958c-eb853f18479d"
      },
      "source": [
        "len(dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82783"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU7lY8dK1ZbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=dict[487025]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq6CS2V11tZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b=dict_old_us[487025]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P060_xZJ2GcQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b34e714-8e9b-45bf-aad6-1eaaf637ba30"
      },
      "source": [
        "a==b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False,  True, ...,  True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuLYbQKt0jjq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "dcc1533d-34b9-4578-b268-42e3e6aba1ac"
      },
      "source": [
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade tables"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/9a/7d474ba0860a41f771c9523d8c4ea56b084840b5ca4092d96bdee8a3b684/numpy-1.19.1-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5MB 227kB/s \n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "Successfully installed numpy-1.19.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tables\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/c3/8fd9e3bb21872f9d69eb93b3014c86479864cca94e625fd03713ccacec80/tables-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables) (2.7.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from tables) (1.19.1)\n",
            "Installing collected packages: tables\n",
            "  Found existing installation: tables 3.4.4\n",
            "    Uninstalling tables-3.4.4:\n",
            "      Successfully uninstalled tables-3.4.4\n",
            "Successfully installed tables-3.6.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tables"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzmEx2UIz_F3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isrORHzKzmpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}